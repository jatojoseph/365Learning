{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "notebook-365.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZoVpoA3CTIp",
        "colab_type": "text"
      },
      "source": [
        "**Steps:** Data(feed)--Model(--Objective Function(Compare)--Optimization Algorithm(vary).\n",
        "Note that this steps are iterative.\n",
        "\n",
        "**Supervised Lrarning** Can be divided into classification and regression.\n",
        "Classsification provides outputs which are categories such as cats or dogs. While Regressionproduces numeric outputs such as 0s, 1s monetary values etc\n",
        "\n",
        "**Unsupervised Learing** Is useful wehn our goal is to split a dataset into a certain number of categories which we do not know prior to implementation(Clustering)\n",
        "\n",
        "**Reinforcememnt Lrarning** We train a model to aact in an enviroment based on the rewards recieved.\n",
        "\n",
        "**Objective function** It is the measure used to evaluate how well the model's output match the desired correct values. Obkective functions are generally split into two: Loss and Reward Functions.\n",
        "\n",
        "**Loss Functions:** The lower the loss function, the higher the level of accuracy of the model.Helps to minimize the error of prediction. Typicallyused in supervised learning\n",
        "\n",
        "**Reward Function:** The higher the reward function, the higher the level of accuracy of the model. They are usually used in reinenforncement learning the goal is to maximise specific results. \n",
        "\n",
        "**Types of Loss Functions**\n",
        "**L2-norm loss(Regression):** The method of calculation is same as that used in ordinary Least Square in stats. \"Norm\" comes from teh fact it is the vector norm, or euclidean distance of the outputs and the targets. The lower the error, the lower the loss.\n",
        "\n",
        "**Cross Entropy(Classification):** \n",
        "\n",
        "The lower the loss, the more accurate the model.\n",
        "\n",
        "Any function that holdds the basic property; Higher for worse results, lower for better results can be a loss function.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wuw9_MUXO1ef",
        "colab_type": "text"
      },
      "source": [
        "## Simple Linear Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1468jki3-y-P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Import the relevant libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mlucp39fPwLQ",
        "colab_type": "code",
        "outputId": "687c8f8a-1c62-4ed7-b313-fa5a427155e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Generate random input data to train on\n",
        "observations = 1000\n",
        "x = np.random.uniform(low=-10, size=(observations, 1))\n",
        "z = np.random.uniform(-10, 10,(observations, 1))\n",
        "\n",
        "# np.stack takes a sequence of 1D arrays and stacks them into a single 2D array\n",
        "inputs = np.column_stack((x,z))\n",
        "\n",
        "inputs.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f076HPRuSKIf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create the target\n",
        "# noise hleps randomize our data a bit. real data always contains noise, it's never perfect\n",
        "noise = np.random.uniform(-1,1,(observations,1))\n",
        "targets = 2*x - 3*z + noise"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4tdEOkyIT0AA",
        "colab_type": "code",
        "outputId": "491fa05a-c981-4f12-ba2c-3cd19f82449e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "# Initialize teh variables\n",
        "init_range = 0.1\n",
        "weights = np.random.uniform(-init_range, init_range, size=(2,1))\n",
        "\n",
        "biases = np.random.uniform(-init_range, init_range, size=1)\n",
        "\n",
        "print(weights)\n",
        "\n",
        "print(biases)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.02661617]\n",
            " [0.04964167]]\n",
            "[0.04240466]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqSipbVrU8E-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set a learning rate\n",
        "\n",
        "learning_rate  = 0.02"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ErTvWf8FVPeC",
        "colab_type": "text"
      },
      "source": [
        "## Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGquW5VvVR5g",
        "colab_type": "code",
        "outputId": "1c8bdd0b-86ac-4647-d725-3f0e31b5979a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for i in range(100):\n",
        "  #calcuates outputs for given weights and biases\n",
        "  outputs = np.dot(inputs, weights) + biases\n",
        "  #deltas record the differece between outputs and targets\n",
        "  deltas = outputs - targets\n",
        "  # print the loss for later analysis\n",
        "  loss = np.sum(deltas **2) /2 / observations\n",
        "\n",
        "  print(loss)\n",
        "  \n",
        "  #update the weights and biases folowing the gradient decent methodology\n",
        "  deltas_scale = deltas / observations\n",
        "\n",
        "  weights = weights - learning_rate * np.dot(inputs.T, deltas_scale)\n",
        "\n",
        "  biases = biases - learning_rate * np.sum(deltas_scale)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "212.92084897633117\n",
            "26.660348508738178\n",
            "3.565955306797402\n",
            "0.617957045146077\n",
            "0.23159448492990553\n",
            "0.17973527954030885\n",
            "0.1725688511293635\n",
            "0.17148823332608912\n",
            "0.1712497630657539\n",
            "0.17113016508092022\n",
            "0.17102847055730758\n",
            "0.17093044471143215\n",
            "0.17083405452836625\n",
            "0.1707389955841188\n",
            "0.1706452097438583\n",
            "0.17055267425834433\n",
            "0.17046137163967348\n",
            "0.17037128534454227\n",
            "0.1702823991523025\n",
            "0.17019469707310442\n",
            "0.17010816333222703\n",
            "0.17002278236539997\n",
            "0.16993853881573912\n",
            "0.169855417530946\n",
            "0.169773403560577\n",
            "0.1696924821533529\n",
            "0.1696126387545075\n",
            "0.16953385900316714\n",
            "0.16945612872976948\n",
            "0.16937943395351476\n",
            "0.1693037608798504\n",
            "0.16922909589799054\n",
            "0.16915542557846736\n",
            "0.16908273667071655\n",
            "0.16901101610069313\n",
            "0.16894025096852025\n",
            "0.16887042854616913\n",
            "0.16880153627516944\n",
            "0.16873356176435067\n",
            "0.16866649278761353\n",
            "0.1686003172817307\n",
            "0.16853502334417744\n",
            "0.1684705992309902\n",
            "0.16840703335465457\n",
            "0.16834431428202182\n",
            "0.16828243073225121\n",
            "0.1682213715747821\n",
            "0.1681611258273312\n",
            "0.16810168265391764\n",
            "0.16804303136291407\n",
            "0.16798516140512354\n",
            "0.1679280623718817\n",
            "0.16787172399318542\n",
            "0.16781613613584476\n",
            "0.16776128880166113\n",
            "0.1677071721256284\n",
            "0.1676537763741593\n",
            "0.16760109194333336\n",
            "0.16754910935717113\n",
            "0.1674978192659288\n",
            "0.1674472124444167\n",
            "0.1673972797903402\n",
            "0.16734801232266228\n",
            "0.16729940117998857\n",
            "0.16725143761897313\n",
            "0.1672041130127462\n",
            "0.16715741884936205\n",
            "0.1671113467302683\n",
            "0.16706588836879577\n",
            "0.167021035588667\n",
            "0.16697678032252652\n",
            "0.16693311461048946\n",
            "0.16689003059871\n",
            "0.16684752053796842\n",
            "0.16680557678227792\n",
            "0.16676419178750856\n",
            "0.16672335811003136\n",
            "0.16668306840537844\n",
            "0.16664331542692282\n",
            "0.16660409202457457\n",
            "0.16656539114349486\n",
            "0.16652720582282718\n",
            "0.16648952919444523\n",
            "0.16645235448171775\n",
            "0.1664156749982895\n",
            "0.16637948414687825\n",
            "0.16634377541808926\n",
            "0.1663085423892434\n",
            "0.16627377872322244\n",
            "0.1662394781673292\n",
            "0.16620563455216275\n",
            "0.16617224179050907\n",
            "0.16613929387624574\n",
            "0.16610678488326244\n",
            "0.1660747089643938\n",
            "0.1660430603503692\n",
            "0.16601183334877384\n",
            "0.16598102234302567\n",
            "0.16595062179136477\n",
            "0.1659206262258566\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8xsbddK60x-F",
        "colab_type": "text"
      },
      "source": [
        "Our output above is a list of numbers that appear in descending order. These are the values of our averaged loss function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5HMTI3J0MAK",
        "colab_type": "code",
        "outputId": "6ab6913b-aabf-4b7e-d737-f7e13d115719",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print(weights, biases)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 1.98008304]\n",
            " [-3.00364718]] [-0.11703092]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJs5kxll2Mfw",
        "colab_type": "text"
      },
      "source": [
        "Plot last output vs target"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U6j6DcrJ13Hf",
        "colab_type": "code",
        "outputId": "65e5ecb7-89ba-4f11-ae38-1c76e7b924df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "plt.plot(outputs, targets)\n",
        "plt.xlabel('Outputs')\n",
        "plt.ylabel('targets')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAEGCAYAAACO8lkDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3deZgU1dXH8e8BWURQJCyiMA4giLvI\nCKKJGyibimZ7lcS4JEFcXhOzGBDEBUGyafTVJGJMNInG3UDcwbgrIig7EgFRQRQ3NpFt5rx/VGFa\nZoapnpnqqu7+fZ5nHrurTk//ZIDD7bp1r7k7IiIimRokHUBERNJHzUFERCpRcxARkUrUHEREpBI1\nBxERqWSnpAPUh9atW3tpaWnSMURE8srMmTM/cvc2VZ0riOZQWlrKjBkzko4hIpJXzOzt6s7pYyUR\nEalEzUFERCpRcxARkUrUHEREpBI1BxERqUTNQUREKkmsOZhZUzObbmazzWy+mV0VHu9kZq+Y2WIz\nu8fMGieVUUSkWCU5ctgEHO/uhwCHAgPM7Ajgl8D17r4P8Cnw/QQzioik0sYt5Vw35T+8t/rzWL5/\nYs3BA+vDp43CLweOB+4Pj98BnJpAPBGR1Lrn1Xfofvnj3PjUmzz/5oexvEeid0ibWUNgJrAPcDOw\nBFjt7lvDkuXAXtW8dhgwDKCkpCT+sCIiCfv0s830GDvli+en9diL/zk8nr//Em0O7l4OHGpmLYGH\ngO5ZvHYiMBGgrKxM29mJSEF6auEHdG7TnOun/IfJs9/74ni3ds25/n8Oje19U7G2kruvNrOngT5A\nSzPbKRw9dABWJJtORCT3Pl6/iZ7XTK3yXI+Sljx4/pGxvn+Ss5XahCMGzGxn4ARgIfA08M2w7Cxg\nUjIJRUSS8afnl1bbGP5y9uE8dMFRmFmsGZIcObQH7givOzQA7nX3h81sAXC3mV0DvA7clmBGEZGc\nWbdxCwdd+WSV53ZqYMwY3Y+WzXIzuz+x5uDuc4AeVRxfCvTKfSIRkeQ89PpyLrlndpXnLunXjYv7\n7hP7aCFTKq45iIgUq883l7PfmMd3WHPOV0tz2hhAy2eIiCTmnlffqbExnHronuzatFGOEv2XRg4i\nIjm2cUs53S/fcVMAmH5ZX9ru2jQHiSpTcxARyaFbnl3CtY+9scOan5zQjYv7ds1RoqqpOYiI5MCi\n99fR/3fP1Vg376r+NG+S/F/NyScQESlwpSMeiVR3+zmHp6IxgJqDiEhsFq5cy8Abnq+xrufeu/PL\nbxzEPm1b5CBVNGoOIiIxiDpa+NU3D+ZbPTvkfKpqTdQcRETq0W0vvMXYhxfUWDfggD0Yd9qBfKV5\nkxykyp6ag4hIPXB3Oo18NFLtXT/ozZH7tI45Ud2oOYiI1NFV/5rPX15cVmPdhcd14X+P70rTRg3j\nD1VHag4iIrWUzWhhyiVH07Vdei4410TNQUSkFobc/CKz311dY93hpbtz73l9UnfBuSZqDiIiWZiz\nfDWn3PRipNppI/uyx27JLH9RV2oOIiIRrN+0lQOveCJS7fnHduEXAyLvepxKag4iIjW4cvJ8bn9p\nWaTatCx/UVeJ/R+YWUfgr0A7wIGJ7n6DmbUC7gFKgWXAt93906Ryikjx2tE+ztsbfHB7bh56WMyJ\ncifJ9rYV+Km7v2ZmLYCZZjYFOBt4yt0nmNkIYATwiwRzikiRcXeG3voKLy/9OFL9/Kv6s0sBjBYy\nJblN6EpgZfh4nZktBPYChgDHhmV3AM+g5iAiOTLz7U/5xh9eily/eNxAdmpYePumpaLVmVkpwX7S\nrwDtwsYB8D7Bx05VvWYYMAygpKQk/pAiUtAqKpzOl0W7ZwHggfOPpOfeu8eYKFmJtzszaw48APzY\n3ddmnnN3J7geUYm7T3T3Mncva9OmTQ6SikihenHxR5EbQ9e2zVk6flBBNwZIeORgZo0IGsOd7v5g\nePgDM2vv7ivNrD2wKrmEIlLItpZXsM+oxyLXTx/Vl7Yt8vO+hWwlNnKw4HbB24CF7n5dxqnJwFnh\n47OASbnOJiKF75E5KyM3hqG9S1g2YXDRNAZIduRwFHAmMNfMZoXHLgMmAPea2feBt4FvJ5RPRArQ\nxi3ldL/88cj1hXLfQraSnK30AlDdYiN9c5lFRIrDtY8t5JZnl0aqPe/ozowctF/MidKr+NqhiBSd\ndRu3cNCVT0auXzJ+EA0b5NdCefVNzUFECtrZf5nOM4s+jFT7vT57c/WQA2NOlB/UHESkIGWz9AXA\n0vGDaFDko4VMag4iUlCy2YAH4JpTD+S7R+wdY6L8pOYgIgXj3U828LVfPR25XqOF6qk5iEjey3bp\ni0v6deNH/brGmCj/qTmISF6bPPs9Lv7H65HrXx3VjzYtmsSYqDCoOYhIXsr2ZrYbz+jBKYfsGWOi\nwqLmICJ5ZfPWCsqumcLajVsjv6ZY73KuC/1qiUjeuG/Gu/z8/jmR628eehiDD24fY6LCpeYgIqm3\neWsF3UZHXz0V4I2xA2jaqGFMiQqfmoOIpNofn13ChMfeiFx/6/fKOGH/KvcIkyyoOYhIKtVmtKD7\nFuqPmoOIpM7l/5zH36a9Hbn+mZ8dS2nrXWJMVHzUHEQkNTZtLWff0dGnpw4+qD03De1BsHeY1Cc1\nBxFJhSE3vcDs5Wsi188ecyK7NWsUY6LilvQe0n8GTgJWufuB4bFWwD1AKbAM+La7f5pURhGJ1+eb\ny9lvTPTRwoSvH8TpvUpiTCSQ/MjhduAm4K8Zx0YAT7n7BDMbET7/RQLZRCRmpSMeyape01NzJ9Hm\n4O7PmVnpdoeHAMeGj+8AnkHNQaSgrNmwhUOujr4z26QLj+KQji1jTCTbS3rkUJV27r4yfPw+UOWE\nZTMbBgwDKCnREFMkX2Q7WtCWnclIY3P4gru7mXk15yYCEwHKysqqrBGR9Fix+nOOmvDvyPXPX3oc\nHVs1izGR7Egam8MHZtbe3VeaWXtgVdKBRKRushktnHLIntxw+qGanpqwNDaHycBZwITwv5OSjSMi\ntfX8mx9y5m3TI9fPHN2PrzTXXgtpkPRU1n8QXHxubWbLgSsImsK9ZvZ94G3g28klFJHayHYfZ4Bl\nEwbHlEZqI+nZSmdUc6pvToOISL257YW3GPvwgsj100b2ZY/dmsaYSGojjR8riUgeKq9wumSxjzNo\ntJBmag4iUmf9rnuWxavWR65/8pKj6dauRYyJpK7UHESk1rJd+qJr2+ZM+ckxMSaS+qLmICK1ku3N\nbAuvHsDOjbX0Rb5QcxCRrEx/6xO+fcvLketHD96PH3ytc4yJJA5qDiISWbajhbeuHaSb2fKUmoOI\n1OjlJR9zxq3TItffe14fenVqFWMiiZuag4hUa93GLRx0ZfTVU0HTUwuFmoOIVKnH1U/y6YYtketf\nHnk87XfbOcZEkktqDiLyJfNWrOGk/3shcn3n1rvw758dG18gSYSag4gAtVsPSdNTC1eDpAOISPIe\nnbsyq8Zw4XFdWDZhsBpDAdPIQaSIVVQ4nbNcD0k7sxUHNQeRIjX6n3P5+7R3ItdPPLMnJx6wR4yJ\nJE3UHESKzOatFXQb/VhWr9H01OKj5iBSRAbf+Dzz31sbuf7FEcezV0tNTy1Gqb0gbWYDzGyRmS02\nsxFJ5xHJZ2s2bKF0xCORG0PbFk1YNmGwGkMRS+XIwcwaAjcDJwDLgVfNbLK7R99eSkSA7NdDWnB1\nf5o1TuVfDZJDaR059AIWu/tSd98M3A0MSTiTSF5ZvGpdVo3hgmOD6alqDAIpHTkAewHvZjxfDvTO\nLDCzYcAwgJKSktwlE8kD2Y4WND1VtpfW5lAjd58ITAQoKyvzhOOIpMKUBR/ww7/OiFx/3/A+HF6q\n1VOlsrQ2hxVAx4znHcJjIlKF2ix9ob0WZEfS2hxeBbqaWSeCpnA6MDTZSCLp9PP7ZnPfzOWR65+/\n9Dg6tmoWYyIpBKlsDu6+1cwuAp4AGgJ/dvf5CccSSZXPN5ez35jHs3qNbmaTqFLZHADc/VEgu3Gy\nSJHoNW4qq9Ztilw/fVRf2rZoGmMiKTSpbQ4iUtknn23msLFTsnqNRgtSG2oOInki2+mpi64ZQJOd\ntKS21E5WN8GZWQMz2zWuMCJS2eJV67NqDD/8WieWTRisxiB1UuPIwczuAoYD5QSziHY1sxvc/ddx\nhxMpZpqeKkmKMnLY393XAqcCjwGdgDNjTSVS5J5etCqrxnDveX1YNmGwGoPUmyjXHBqZWSOC5nCT\nu2/Rb0CReGzcUk73yzU9VZIXpTncAiwDZgPPmdnewJo4Q4kUo6/+8t8s//TzyPW6mU3iFKU5/Mvd\nb9z2xMzeAc6NL5JIcfl4/SZ6XjM1q9dotCBxi9IcHgAO2/bE3d3M7gZ6xpZKpEhorwVJq2p/l5lZ\nd+AAYDcz+3rGqV0B3WopUgcLV65l4A3PR64/tGNL/nnhUTEmEvmyHf0TZF/gJKAlcHLG8XXAD+MM\nJVKoajM9den4QTTQXguSY9U2B3efBEwysz7u/nIOM4kUpMmz3+Pif7weuX78aQcxtLc2spJkRPnw\n8mMzewpo5+4HmtnBwCnufk3M2UQKwuatFXQb/VhWr9EFZ0lalJvgbgVGAlsA3H0Owf4KIlKDW59b\nmlVjePh/v6rGIKkQZeTQzN2nb3fj29aY8ogUhLUbt3DwlU9m9Ro1BUmTKM3hIzPrAjiAmX0TWBlr\nKpE8NvTWaby05OPI9a9dfgKtdmkcYyKR7EX5WOlCgruku5vZCuDHwPl1eVMz+5aZzTezCjMr2+7c\nSDNbbGaLzKx/Xd5HJJdWrP6c0hGPZNUYlk0YrMYgqVTjyMHdlwL9zGwXoIG7r6uH950HfJ2g6XzB\nzPYnuJ5xALAnMNXMurl7eT28p0gsKiqczpdlNz31zXEDadQwqxXzRXIqypLdP9nuOQRrK81091m1\neVN3X5jxvTINAe52903AW2a2GOgFaCqtpNIzi1Zx9l9ejVz/9cP24rpvHxpjIpH6EeWaQ1n49a/w\n+UnAHGC4md3n7r+qxzx7AdMyni8Pj4mkSm1WT9VeC5JPojSHDsBh7r4ewMyuAB4BjgZmAlU2BzOb\nCuxRxalR4Q12dWJmw4BhACUlulFIcmfic0sY/+gbkev/74wenHzInjEmEql/UZpDW2BTxvMtBDfE\nfW5mm6p5De7erxZ5VgAdM553CI9V9f0nAhMBysrKvBbvJZIVTU+VYhKlOdwJvGJm2/61fzJwV3iB\nekE955kcfu/rCC5IdwWm1/N7iGRt9D/n8vdp70Suv+2sMvru1y7GRCLx2mFzsOAD0tsJtgfdtiTk\ncHefET7+Tm3e1MxOA/4PaAM8Ymaz3L2/u883s3sJms5W4ELNVJIkfbR+E2VZ7rWweNxAdtJMJMlz\n5r7jT2TMbK67H5SjPLVSVlbmM2bMqLlQJAvXPLyAP73wVuT6qT85mn3atogxkUj9MrOZ7l5W1bko\nHyu9ZmaHu3v0+XoieWxreQX7jNJCeVLcojSH3sB3zOxt4DPACDaEOzjWZCIJOPsv03lm0YeR6+de\neSItmjaKMZFIMqI0By1hIQVvw+at7D/micj1/Q9oxy1nVjkaFykIUZbPeBvAzNqi7UGlAGW7j/OS\n8YNoqJ3ZpMBFWT7jFOC3BFNLVwF7AwsJ1j8SyVuLV62j33XPRa6/aWgPTjpYN7NJcYjysdJY4Ahg\nqrv3MLPjgO/GG0skPrVZKE8XnKXYRGkOW9z9YzNrYGYN3P1pM/td7MlEYvDga8v5yb2zI9c/f+lx\ndGzVLMZEIukUpTmsNrPmwHPAnWa2ClgfbyyR+qXpqSLZidIcZgMbgEsI7ojeDWgeZyiR+vSL++dw\nz4x3I9e/MXYATRs1jDGRSPpFaQ7HuXsFUAHcAWBmc2JNJVIPPv1sMz3GTolc36fzV/jHsCNiTCSS\nP6ptDmZ2PnAB0GW7ZtACeDHuYCK15e50GpndBWfttSDyZTsaOdxFsODetcCIjOPr3P2TWFOJ1NKc\n5as55abo/3b59TcP5ltlHWsuFCky1TYHd19DsB3oGbmLI1I7tRkt6IKzSPWiXHMQSbVZ767m1Juj\njxbuG96Hw0tbxZhIJP+pOUjeKq9wuuhmNpFYqDlIXvrby8u4fNL8yPWvX34Cu+/SOL5AIgVGzUHy\nSrb7OLfapTGvXX5CjIlEClMizcHMfk2wF/VmYAlwjruvDs+NBL4PlAMXu3v0dZSlYNXmgvOb4wbS\nSNt1itRKUn9ypgAHhhsG/QcYCWBm+wOnE6z4OgD4vZnpVtUiN23px1k1hvOO6cyyCYPVGETqIJGR\ng7tnfi4wDfhm+HgIcLe7bwLeMrPFQC/g5RxHlJTIdq8F3cwmUj/ScM3hXOCe8PFeBM1im+XhsUrM\nbBgwDKCkpCTOfJKAVWs30mv8U5HrbzmzJ/0P2CPGRCLFJbbmYGZTgar+tI5y90lhzShgK3Bntt/f\n3ScCEwHKysq8DlElZbIdLWh6qkj9i605uHu/HZ03s7OBk4C+7r7tL/cVQOZaBh3CY1IEnpj/Puf9\nbWbk+imXHE3Xdi1iTCRSvJKarTQAuBQ4xt03ZJyaDNxlZtcRbEvaFZieQETJIS19IZI+SV1zuAlo\nAkwJLx5Oc/fh7j7fzO4FFhB83HShu5cnlFFyINud2XQzm0huJDVbaZ8dnBsHjMthHEnApq3l7Dv6\n8cj1rZs3ZsZo3cwmkitpmK0kReZHd7/OpFnvRa6ff1V/dmmi36oiuaQ/cZIzH6/fRM9rpkauP/XQ\nPfnd6T1iTCQi1VFzkNhVVDids1w9Vfs4iyRLzUFiNXf5Gk6+6YXI9T/vvy8XHlftJSkRyRE1B4lF\nthecQdNTRdJEzUHq3ctLPuaMW6fVXBh6acTx7Nly5xgTiUi21Byk3uhmNpHCoeYg9eKBmcv56X3R\nb2abe+WJtGjaKMZEIlIXag5SJ2s2bOGQq6PvzNa2RROmj9rhslsikgJqDlIrFRXOKTe/wLwVayO/\nZuHVA9i5saaniuQDNQfJ2pzlqznlphcj1+tmNpH8o+YgkX362WZ6jJ2S1Wt0M5tIflJzkEjWbdyS\nVWO46Lh9+Fn/fWNMJCJxUnOQGmW7M5tGCyL5T81BqrX0w/Uc/9tnI9ePHrwfP/ha5xgTiUiuqDlI\nJdnezNawgbFk/KAYE4lIriW1TehYYAhQAawCznb39yzYFu4GYBCwITz+WhIZi9Wtzy1l3KMLI9fr\nIySRwpTUyOHX7n45gJldDIwBhgMDCfaN7gr0Bv4Q/lditnlrBd1GPxa5fuCBe/CH7/aMMZGIJCmp\nbUIz75zaBfDw8RDgr+7uwDQza2lm7d19Zc5DFpFL7pnFQ6+viFy/eNxAdmrYIMZEIpK0xK45mNk4\n4HvAGuC48PBewLsZZcvDY5Wag5kNA4YBlJSUxJq1UL23+nOOnPDvyPW64CxSPGJrDmY2FdijilOj\n3H2Su48CRpnZSOAi4Ipsvr+7TwQmApSVlXkN5ZKhNqunLh0/iAYNLKZEIpI2sTUHd4+6utqdwKME\nzWEF0DHjXIfwmNSTx+au5Pw7o1/j//v3e/PVrq1jTCQiaZTUbKWu7v5m+HQI8Eb4eDJwkZndTXAh\neo2uN9Sf/cc8zobN5ZHrtdeCSPFK6prDBDPbl2Aq69sEM5UgGEEMAhYTTGU9J5l4hWXjlnK6Xx59\ny87ZY05kt2baa0GkmCU1W+kb1Rx34MIcxylo2Sx90X2PFjz+46NjTCMi+UJ3SBeobGci6WY2Ecmk\n5lCAshktnHtUJ8acvH+MaUQkH6k5FJCXFn/E0D+9Erl+yfhBNNT0VBGpgppDAcj2voVxpx3Id3rv\nHWMiEcl3ag55bvGq9fS7Lvqy2m9dO4hgfUMRkeqpOeSp8gqny2XRRwt3nNuLY7q1iTGRiBQSNYc8\ntOC9tQy68flItT333p0Hzj8y5kQiUmjUHPLIxi3lHHHtU6zesCVSvW5mE5HaUnPIEy+8+RHfvS3a\nTKTv9C5h3GkHxZxIRAqZmkPKrfl8C4dc9WTket3MJiL1Qc0hxe6fuZyf3Tc7Uu2Igd0ZfkyXmBOJ\nSLFQc0ihD9ZupPf4pyLXa2c2Ealvag4pUlHh/ObJRfz+mSWR6l8acTx7ttw55lQiUozUHFJiyYfr\n6fvbaDeznXNUKVecfEDMiUSkmKk5JGzz1gqG3jqNGW9/Gql+/lX92aWJfmwiEi/9LZOg1975lK//\n/qVItVedcgBnHVkabyARkVCizcHMfgr8Bmjj7h9ZsOjPDQS7wW0Aznb36Bse54nPNm3lgCueiFy/\n6JoBNNlJ01NFJHcSaw5m1hE4EXgn4/BAoGv41Rv4Q/jfgvHo3JVccGe0fvfbbx3CN3p2iDmRiEhl\nSY4crgcuBSZlHBsC/DXcLnSambU0s/buvjKRhPXo4/Wb6HnN1Mj12mtBRJKUSHMwsyHACnefvd3y\n0XsB72Y8Xx4eq9QczGwYMAygpKQkvrB15O5MePwNbnl2aaT6u37QmyP3aR1zKhGRHYutOZjZVGCP\nKk6NAi4j+Eip1tx9IjARoKyszOvyveKy9MP1HB9xeiporwURSY/YmoO796vquJkdBHQCto0aOgCv\nmVkvYAXQMaO8Q3gsr2wtr+C7t73CtKWfRKq/f3gfykpbxZxKRCS6nH+s5O5zgbbbnpvZMqAsnK00\nGbjIzO4muBC9Jt+uN0xb+jGnT5wWuV6jBRFJo7Td5/AowTTWxQRTWc9JNk50G7eU0/3yxyPXP3jB\nkRxWsnuMiUREai/x5uDupRmPHbgwuTS1c9cr73DZQ3Mj12u0ICJpl3hzyGer1m2k17joq6dqtCAi\n+ULNoRbcnZ/fP4f7Zy6PVH/7OYdz7L5tay4UEUkJNYcszV2+hpNveiFyvW5mE5F8pOaQhUmzVvCj\nu2dFqn3ykqPp1q5FzIlEROKh5hDR1f9awJ9ffCtSrS44i0i+U3OoweJV6+h33XORarUzm4gUCjWH\nHfjPB+s48fqaG8MRnVtx97A+OUgkIpIbag7VmPjcEsY/+kaNdbPGnEDLZo1zkEhEJHfUHLbz/pqN\nHHFtzfcuDO1dwvjTDspBIhGR3FNzyDDywTn8Y/q7O6zpt19b/nTW4TlKJCKSDDUH4IO1G+k9vubR\nwryr+tO8iX7JRKTw6W864OE5O174dcTA7gw/pkuO0oiIJK/om8Mtzy7h2seqvvC8525N+ffPjqVp\no4Y5TiUikqyibg6L3l/3pcbQtW1zLh3QnTdWruWM3iW0bt4kwXQiIskp6ubQZKcGXzz+yQndGH5M\nFxrv1IAT9m+XYCoRkeQVdXPYvVljfvDVTpzeq4R92jZPOo6ISGo0qLmk/pnZlWa2wsxmhV+DMs6N\nNLPFZrbIzPrHmWO3Zo0YfdL+agwiIttJcuRwvbv/JvOAme0PnA4cAOwJTDWzbu5enkRAEZFilcjI\nYQeGAHe7+yZ3f4tgL+leCWcSESk6STaHi8xsjpn92cy27Z25F5B5i/Ly8FglZjbMzGaY2YwPP/ww\n7qwiIkUltuZgZlPNbF4VX0OAPwBdgEOBlcBvs/3+7j7R3cvcvaxNmzb1nF5EpLjFds3B3ftFqTOz\nW4GHw6crgI4ZpzuEx0REJIeSmq3UPuPpacC88PFk4HQza2JmnYCuwPRc5xMRKXZJzVb6lZkdCjiw\nDDgPwN3nm9m9wAJgK3ChZiqJiOReIs3B3c/cwblxwLgcxhERke2Yuyedoc7M7EPg7WpOtwY+ymGc\nbKU5n7LVjrLVTpqzQbrz1Tbb3u5e5YyegmgOO2JmM9y9LOkc1UlzPmWrHWWrnTRng3TniyNb2m6C\nExGRFFBzEBGRSoqhOUxMOkAN0pxP2WpH2Wonzdkg3fnqPVvBX3MQEZHsFcPIQUREsqTmICIilRRs\nc0jLhkI1ZPypmbmZtQ6fm5ndGGabY2aHJZBpbPjes8zsSTPbMy3Zwhy/NrM3wgwPmVnLjHOJ/lzN\n7FtmNt/MKsysbLtzif+eM7MB4fsvNrMRSWTIyPJnM1tlZvMyjrUysylm9mb439139D1izNbRzJ42\nswXhz/NHaclnZk3NbLqZzQ6zXRUe72Rmr4Q/23vMrHGd38zdC/ILuBL4WRXH9wdmA02ATsASoGEC\n+ToCTxDcvNc6PDYIeAww4AjglQRy7Zrx+GLgj2nJFuY4EdgpfPxL4Jdp+bkC+wH7As8AZWn6PQc0\nDN+3M9A4zLN/Ej/DMM/RwGHAvIxjvwJGhI9HbPvZJpCtPXBY+LgF8J/wZ5h4vvDPX/PwcSPglfDP\n473A6eHxPwLn1/W9CnbksANp2VDoeuBSgvWlMrP91QPTgJbbLVIYO3dfm/F0l4x8iWcL8z3p7lvD\np9MIVu7dli/Rn6u7L3T3RVWcSjxb+H6L3X2pu28G7g5zJcLdnwM+2e7wEOCO8PEdwKk5DRVy95Xu\n/lr4eB2wkGBfmcTzhX/+1odPG4VfDhwP3F+f2Qq9OdRpQ6G4hHtarHD32dudSjwbgJmNM7N3ge8A\nY9KUbTvnEoxmIJ35tklDtjRkqEk7d18ZPn4faJdkGAAzKwV6EPwLPRX5zKyhmc0CVgFTCEaEqzP+\n0VQvP9sk95CuMzObCuxRxalRBBsKjSXoqmMJNhQ6NyXZLiP4eCQRO8rm7pPcfRQwysxGAhcBV6Qp\nX1gzimDl3jvTlk3qzt3dzBKdZ29mzYEHgB+7+1oz++Jckvk8WKn60PB620NA9zjeJ6+bg6d4Q6Hq\nspnZQQSfO88Of7N1AF4zs15JZ6vCncCjBM0hZxsx1ZTPzM4GTgL6evgha67yZfFrlykNm1ilIUNN\nPjCz9u6+MvzIclVSQcysEUFjuNPdH0xbPgB3X21mTwN9CD7m3SkcPdTLz7ZgP1aylG4o5O5z3b2t\nu5e6eynBEPAwd38/zPa9cGbQEcCajGFsTphZ14ynQ4A3wseJZwvzDSC4VnOKu2/IOJXmjaLSkO1V\noGs4q6UxcHqYK00mA2eFj88CEhmJWfCvttuAhe5+XcapxPOZWZttM/TMbGfgBIJrIk8D36zXbLm+\n2p6rL+BvwFxgDsEPtX3GuVEEn9MtAgYmnHMZ/52tZMDNYba5ZMx4yWGeBwga6RzgX8BeackW5lhM\n8Nn5rPDrj2n5uRL8I2Q5sJ6fgs0AAAKHSURBVAn4AHgiLdnCDIMIZt4sIfgYLOcZMrL8g2D/+C3h\nr9n3ga8ATwFvAlOBVgll+yrBx9FzMn6fDUpDPuBg4PUw2zxgTHi8M8E/OBYD9wFN6vpeWj5DREQq\nKdiPlUREpPbUHEREpBI1BxERqUTNQUREKlFzEBGRStQcRKpgZh3MbFK4AucSM7uhppUuzeyyOr7n\nsWZ2ZF2+h0h9UXMQ2U54E9SDwD/dvSvQDWgOjKvhpXVqDsCxgJqDpIKag0hlxwMb3f0v8MVaNpcA\n55rZBWZ207ZCM3s4/Bf/BGBnC/bBuNPMSi3Yd+JOM1toZvebWbPwNcvsv3t4lJnZM+ECb8OBS8Lv\n8TUL9oeYF67d/1xufwmk2Kk5iFR2ADAz84AHS5m/QzXrkbn7COBzdz/U3b8THt4X+L277wesBS6o\n7g3dfRnBOvzXh9/jeYIVcfu7+yHAKXX7XxLJjpqDSHzedfcXw8d/J1iWIRsvAreb2Q8JNusRyRk1\nB5HKFgA9Mw+Y2a5ACbCaL/+5abqD77P92jTbnm/N+B7Vvt7dhwOjCVZTnWlmX6kxuUg9UXMQqewp\noJmZfQ+CzVUI9gO5HVhKsJZ+AzPryJd3dNsSLvW8TYmZ9QkfDwVeCB8v47/N5xsZ9esItqUkfN8u\n7v6Ku48BPuTLS26LxErNQWQ7HqxGeRrwLTN7k2Al040Es5FeBN4iGF3cCLyW8dKJwBwz27YB0SLg\nQjNbCOxOsAEVwFXADWY2AyjPeP2/gNO2XZAGfm1mc81sHvASwb7PIjmhVVlFYhDOPnrY3Q9MOIpI\nrWjkICIilWjkICIilWjkICIilag5iIhIJWoOIiJSiZqDiIhUouYgIiKV/D/wxAAvyJfLOwAAAABJ\nRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KQyrBVHR3EJC",
        "colab_type": "text"
      },
      "source": [
        "From above, the closer the price is to a 45 degree line, the closer target and output values are"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pf0UDs9psXec",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6BiHB-SdsY7M",
        "colab_type": "text"
      },
      "source": [
        "## TensorFlow Deep Dive\n",
        "\n",
        "One of the major advantages of TF is that it uses both CPU and GPU, TPU which helps speeds up the algorithm.\n",
        "Tensorflow does'nt work well with .csv or xlxs files. it is tensor based, therefoer, works better with tensors. \n",
        ".npz files(numpy file type) which allows u store nd arrays.\n",
        "Tensors can be represented as n-dimensional arrays\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GngyRzQ0uCAQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9D9UltNLuTqS",
        "colab_type": "text"
      },
      "source": [
        "## Data Integration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ir4umo9HuXqq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "observations = 1000\n",
        "xs = np.random.uniform(low = -10, high=10, size=(observations, 1))\n",
        "zs = np.random.uniform(-10, 10, (observations, 1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MtZEXgJpv45P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "generated_inputs = np.column_stack((xs, zs))\n",
        "\n",
        "noise = np.random.uniform(-1, 1, (observations, 1))\n",
        "\n",
        "generated_targets = 2*zs - 3*zs + 5 + noise"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PsljGuLUwXKQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.savez('TF_intro', inputs =generated_inputs, targets=generated_targets)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZuKxtnyGyCD0",
        "colab_type": "text"
      },
      "source": [
        "## Solving with TF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKl8KUA6x_QX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_data = np.load('TF_intro.npz')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7JUgGe6Ox7z_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_size = 2\n",
        "output_size =1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7084hnKFwrqu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "                             tf.keras.layers.Dense(output_size)\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_jE2c4QgyyN2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='sgd', loss ='mean_squared_error')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GkbwAbHXzNbf",
        "colab_type": "code",
        "outputId": "beabd9f3-34da-4f71-9e48-b45bf68879cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model.fit(training_data['inputs'], training_data['targets'], epochs=100, verbose=0)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f84fa58cac8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6LnItyz0QLO",
        "colab_type": "text"
      },
      "source": [
        "## Extract the weights and bias"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70zjHTx8zo87",
        "colab_type": "code",
        "outputId": "05988048-4f35-4687-c8fd-1fc9edcd3b0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "model.layers[0].get_weights()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[-0.01847873],\n",
              "        [-0.97272956]], dtype=float32), array([4.985204], dtype=float32)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQ7-fwR80amh",
        "colab_type": "code",
        "outputId": "24ada4a0-f0be-4ffd-c0f5-63d63d5c6a11",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "bias = model.layers[0].get_weights()[1]\n",
        "bias"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([4.985204], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yiLKyZ7q06AH",
        "colab_type": "text"
      },
      "source": [
        "## Extract the outputs (Make predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cSk2-noJ00uQ",
        "colab_type": "code",
        "outputId": "58824788-fb16-4bb4-d7b1-35634be203ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.predict_on_batch(training_data['inputs']).round(1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-1.1],\n",
              "       [ 3.8],\n",
              "       [ 4.2],\n",
              "       [11.8],\n",
              "       [-4.4],\n",
              "       [12. ],\n",
              "       [12.5],\n",
              "       [ 7.1],\n",
              "       [-1.1],\n",
              "       [-1.9],\n",
              "       [-4.5],\n",
              "       [10. ],\n",
              "       [-4. ],\n",
              "       [10.6],\n",
              "       [ 8.9],\n",
              "       [ 6.2],\n",
              "       [ 4. ],\n",
              "       [ 0.2],\n",
              "       [ 5.5],\n",
              "       [ 2.1],\n",
              "       [13.8],\n",
              "       [10.4],\n",
              "       [ 9.4],\n",
              "       [ 7.2],\n",
              "       [ 1. ],\n",
              "       [-4.6],\n",
              "       [ 8.8],\n",
              "       [ 5.2],\n",
              "       [13.2],\n",
              "       [ 4. ],\n",
              "       [-1.6],\n",
              "       [ 9.5],\n",
              "       [ 1.4],\n",
              "       [12.2],\n",
              "       [14.1],\n",
              "       [-1.2],\n",
              "       [ 5.5],\n",
              "       [13.6],\n",
              "       [ 2.7],\n",
              "       [ 0.4],\n",
              "       [ 7.1],\n",
              "       [ 6.8],\n",
              "       [-0.5],\n",
              "       [12.4],\n",
              "       [ 2.5],\n",
              "       [-3.1],\n",
              "       [13.4],\n",
              "       [11.2],\n",
              "       [ 9.6],\n",
              "       [ 0.6],\n",
              "       [13.7],\n",
              "       [ 2.1],\n",
              "       [13.6],\n",
              "       [ 0.5],\n",
              "       [-2.2],\n",
              "       [-4.3],\n",
              "       [ 6.6],\n",
              "       [-2.4],\n",
              "       [-2. ],\n",
              "       [ 0.2],\n",
              "       [-3.2],\n",
              "       [ 2.1],\n",
              "       [ 6. ],\n",
              "       [13.7],\n",
              "       [ 9.6],\n",
              "       [ 6.8],\n",
              "       [-2. ],\n",
              "       [10.5],\n",
              "       [10.9],\n",
              "       [13.3],\n",
              "       [ 5.5],\n",
              "       [ 2.7],\n",
              "       [-0.2],\n",
              "       [ 8. ],\n",
              "       [-3. ],\n",
              "       [ 3.8],\n",
              "       [14.5],\n",
              "       [-2.7],\n",
              "       [ 9.2],\n",
              "       [11.4],\n",
              "       [ 3.2],\n",
              "       [ 5.4],\n",
              "       [-2. ],\n",
              "       [-3.8],\n",
              "       [10.5],\n",
              "       [14.5],\n",
              "       [10.9],\n",
              "       [ 7. ],\n",
              "       [ 6.5],\n",
              "       [11.4],\n",
              "       [-0.3],\n",
              "       [-0.9],\n",
              "       [ 4.5],\n",
              "       [-1.5],\n",
              "       [-1.1],\n",
              "       [-0.3],\n",
              "       [ 7.6],\n",
              "       [ 9.8],\n",
              "       [ 9.1],\n",
              "       [ 3.3],\n",
              "       [ 1.1],\n",
              "       [ 2.7],\n",
              "       [-3.1],\n",
              "       [14. ],\n",
              "       [ 3.3],\n",
              "       [ 5.4],\n",
              "       [11.9],\n",
              "       [12.7],\n",
              "       [ 8.3],\n",
              "       [ 1.2],\n",
              "       [-0.1],\n",
              "       [-2. ],\n",
              "       [-2.9],\n",
              "       [-4.8],\n",
              "       [-0.4],\n",
              "       [ 1.5],\n",
              "       [-4.1],\n",
              "       [-4.4],\n",
              "       [ 9. ],\n",
              "       [-4. ],\n",
              "       [ 6.4],\n",
              "       [11.1],\n",
              "       [14.5],\n",
              "       [ 7.4],\n",
              "       [ 9.4],\n",
              "       [ 4.9],\n",
              "       [ 8. ],\n",
              "       [ 4.6],\n",
              "       [ 1.5],\n",
              "       [14.4],\n",
              "       [-0.7],\n",
              "       [ 8.2],\n",
              "       [-0.3],\n",
              "       [13.1],\n",
              "       [12.5],\n",
              "       [ 9.1],\n",
              "       [11.9],\n",
              "       [-4.4],\n",
              "       [-0.8],\n",
              "       [ 6.4],\n",
              "       [ 6.4],\n",
              "       [-3.7],\n",
              "       [-3.4],\n",
              "       [-2.4],\n",
              "       [ 9.1],\n",
              "       [-2.2],\n",
              "       [11.8],\n",
              "       [ 2.3],\n",
              "       [-1.8],\n",
              "       [-0.7],\n",
              "       [11.7],\n",
              "       [ 4.4],\n",
              "       [ 8.1],\n",
              "       [ 2.7],\n",
              "       [ 6.6],\n",
              "       [11.2],\n",
              "       [ 2.9],\n",
              "       [-2.8],\n",
              "       [ 3.4],\n",
              "       [-2. ],\n",
              "       [14.1],\n",
              "       [ 5.4],\n",
              "       [13.7],\n",
              "       [-2.8],\n",
              "       [ 4.1],\n",
              "       [12.1],\n",
              "       [ 8. ],\n",
              "       [-3.2],\n",
              "       [ 8.6],\n",
              "       [ 3.5],\n",
              "       [-1. ],\n",
              "       [ 6.5],\n",
              "       [ 8. ],\n",
              "       [ 4.8],\n",
              "       [-0.9],\n",
              "       [ 3. ],\n",
              "       [ 8.9],\n",
              "       [ 7.6],\n",
              "       [14.5],\n",
              "       [ 5.3],\n",
              "       [ 1.8],\n",
              "       [-3.8],\n",
              "       [ 8.7],\n",
              "       [-0.9],\n",
              "       [ 0.2],\n",
              "       [-3.9],\n",
              "       [ 0.6],\n",
              "       [ 9.2],\n",
              "       [-3.9],\n",
              "       [ 4.1],\n",
              "       [-3.4],\n",
              "       [10.7],\n",
              "       [ 7.6],\n",
              "       [ 4.1],\n",
              "       [ 7.3],\n",
              "       [10.9],\n",
              "       [10.3],\n",
              "       [-3.5],\n",
              "       [10.3],\n",
              "       [-0.3],\n",
              "       [11.5],\n",
              "       [ 7.9],\n",
              "       [ 2.2],\n",
              "       [ 9.5],\n",
              "       [13.9],\n",
              "       [ 3.6],\n",
              "       [ 2. ],\n",
              "       [ 6. ],\n",
              "       [ 5.7],\n",
              "       [ 5.6],\n",
              "       [-3.7],\n",
              "       [ 3.2],\n",
              "       [ 2.9],\n",
              "       [11.5],\n",
              "       [-1.7],\n",
              "       [11.6],\n",
              "       [-0.1],\n",
              "       [ 8.3],\n",
              "       [ 5.6],\n",
              "       [ 5.4],\n",
              "       [10. ],\n",
              "       [-3.5],\n",
              "       [ 9.6],\n",
              "       [ 4.6],\n",
              "       [ 0.4],\n",
              "       [ 0.1],\n",
              "       [11.2],\n",
              "       [-1.7],\n",
              "       [-0.2],\n",
              "       [ 2.5],\n",
              "       [ 2.8],\n",
              "       [12.3],\n",
              "       [ 9.3],\n",
              "       [ 9. ],\n",
              "       [14.4],\n",
              "       [ 5.8],\n",
              "       [-1.7],\n",
              "       [ 7.3],\n",
              "       [-3.4],\n",
              "       [-1. ],\n",
              "       [ 7.6],\n",
              "       [13.7],\n",
              "       [ 6. ],\n",
              "       [ 3.7],\n",
              "       [-3. ],\n",
              "       [10.8],\n",
              "       [11. ],\n",
              "       [14.2],\n",
              "       [-0.7],\n",
              "       [11.4],\n",
              "       [ 5.4],\n",
              "       [11.1],\n",
              "       [12.4],\n",
              "       [12. ],\n",
              "       [ 6. ],\n",
              "       [ 2.1],\n",
              "       [-4.5],\n",
              "       [ 4.5],\n",
              "       [ 8.9],\n",
              "       [ 1.8],\n",
              "       [ 3.5],\n",
              "       [14.7],\n",
              "       [ 4.7],\n",
              "       [ 0.2],\n",
              "       [14.3],\n",
              "       [ 7.7],\n",
              "       [-2.7],\n",
              "       [12.7],\n",
              "       [12.1],\n",
              "       [-0.4],\n",
              "       [-4.5],\n",
              "       [-1. ],\n",
              "       [11.4],\n",
              "       [ 3.2],\n",
              "       [ 6.5],\n",
              "       [ 9. ],\n",
              "       [-0.5],\n",
              "       [ 5.8],\n",
              "       [-0.2],\n",
              "       [ 3.6],\n",
              "       [ 0.7],\n",
              "       [-4.7],\n",
              "       [-2.7],\n",
              "       [ 4.8],\n",
              "       [-3.7],\n",
              "       [14.3],\n",
              "       [ 2.7],\n",
              "       [11.1],\n",
              "       [ 4.2],\n",
              "       [ 9.6],\n",
              "       [-2.1],\n",
              "       [10. ],\n",
              "       [ 4.7],\n",
              "       [-1.7],\n",
              "       [ 1.4],\n",
              "       [ 7.1],\n",
              "       [-4. ],\n",
              "       [11.4],\n",
              "       [ 3. ],\n",
              "       [ 6.2],\n",
              "       [ 7.5],\n",
              "       [ 1.4],\n",
              "       [-3. ],\n",
              "       [10. ],\n",
              "       [ 6.5],\n",
              "       [-2.8],\n",
              "       [13.1],\n",
              "       [ 0.9],\n",
              "       [-2.7],\n",
              "       [ 7. ],\n",
              "       [-4.5],\n",
              "       [-4.5],\n",
              "       [ 7.9],\n",
              "       [ 4.1],\n",
              "       [10.8],\n",
              "       [11.1],\n",
              "       [ 0.1],\n",
              "       [ 8.6],\n",
              "       [-2.7],\n",
              "       [ 0.2],\n",
              "       [ 0.5],\n",
              "       [12.1],\n",
              "       [12.4],\n",
              "       [ 8.4],\n",
              "       [ 7.3],\n",
              "       [ 6.1],\n",
              "       [-1.7],\n",
              "       [ 8.7],\n",
              "       [ 8. ],\n",
              "       [ 1.2],\n",
              "       [10.3],\n",
              "       [ 4.8],\n",
              "       [-0.3],\n",
              "       [-3.2],\n",
              "       [ 5.3],\n",
              "       [ 1. ],\n",
              "       [ 6. ],\n",
              "       [14.1],\n",
              "       [-2.1],\n",
              "       [ 1.9],\n",
              "       [ 7.5],\n",
              "       [ 0.8],\n",
              "       [14.3],\n",
              "       [ 6.5],\n",
              "       [ 6.3],\n",
              "       [14.4],\n",
              "       [ 3.6],\n",
              "       [-2. ],\n",
              "       [-0.5],\n",
              "       [-0.6],\n",
              "       [ 0.3],\n",
              "       [ 3.3],\n",
              "       [10.2],\n",
              "       [14.3],\n",
              "       [-2.8],\n",
              "       [10.1],\n",
              "       [-2.7],\n",
              "       [ 8.8],\n",
              "       [-3.3],\n",
              "       [10.1],\n",
              "       [11.9],\n",
              "       [13.7],\n",
              "       [12.5],\n",
              "       [-1.4],\n",
              "       [12.5],\n",
              "       [ 9. ],\n",
              "       [ 9.4],\n",
              "       [ 4.9],\n",
              "       [ 7.7],\n",
              "       [ 3.5],\n",
              "       [ 8.8],\n",
              "       [-1.5],\n",
              "       [ 5.4],\n",
              "       [-3.5],\n",
              "       [-2.3],\n",
              "       [-3.4],\n",
              "       [-3.9],\n",
              "       [ 7.3],\n",
              "       [-3.4],\n",
              "       [ 9.3],\n",
              "       [ 6.8],\n",
              "       [ 5.6],\n",
              "       [-4.5],\n",
              "       [10.6],\n",
              "       [-0.1],\n",
              "       [ 6.7],\n",
              "       [ 5. ],\n",
              "       [ 5.4],\n",
              "       [ 8.3],\n",
              "       [12.4],\n",
              "       [ 5. ],\n",
              "       [ 8.2],\n",
              "       [-0.2],\n",
              "       [ 9.1],\n",
              "       [14.6],\n",
              "       [ 7.1],\n",
              "       [ 6. ],\n",
              "       [12.9],\n",
              "       [-3.5],\n",
              "       [-1.6],\n",
              "       [ 9.7],\n",
              "       [ 1.8],\n",
              "       [12.1],\n",
              "       [ 0.5],\n",
              "       [10.2],\n",
              "       [ 9.2],\n",
              "       [11.6],\n",
              "       [ 0.9],\n",
              "       [ 4.9],\n",
              "       [ 3.6],\n",
              "       [ 2.6],\n",
              "       [-2.1],\n",
              "       [ 5.6],\n",
              "       [12.6],\n",
              "       [-4.1],\n",
              "       [ 4.4],\n",
              "       [ 3.7],\n",
              "       [ 8.2],\n",
              "       [ 7.3],\n",
              "       [ 0.9],\n",
              "       [ 6.9],\n",
              "       [ 0.6],\n",
              "       [-0.3],\n",
              "       [-4.4],\n",
              "       [13.1],\n",
              "       [-4.3],\n",
              "       [ 1.5],\n",
              "       [ 2.6],\n",
              "       [ 6.1],\n",
              "       [-4.4],\n",
              "       [ 6. ],\n",
              "       [11.4],\n",
              "       [ 1.8],\n",
              "       [ 3.9],\n",
              "       [ 8. ],\n",
              "       [ 8.3],\n",
              "       [12.1],\n",
              "       [14.1],\n",
              "       [12.8],\n",
              "       [ 7. ],\n",
              "       [ 4.4],\n",
              "       [-1.3],\n",
              "       [13.1],\n",
              "       [ 8. ],\n",
              "       [-3.6],\n",
              "       [ 8.1],\n",
              "       [ 0.7],\n",
              "       [-3.2],\n",
              "       [-4.4],\n",
              "       [ 7.8],\n",
              "       [-1. ],\n",
              "       [ 9.8],\n",
              "       [13.3],\n",
              "       [ 7.5],\n",
              "       [-3.8],\n",
              "       [-3.5],\n",
              "       [ 9. ],\n",
              "       [-4.6],\n",
              "       [12.1],\n",
              "       [ 7.4],\n",
              "       [11.6],\n",
              "       [-4.7],\n",
              "       [-2.1],\n",
              "       [-0.9],\n",
              "       [ 8. ],\n",
              "       [10.9],\n",
              "       [14.3],\n",
              "       [ 3.4],\n",
              "       [ 4. ],\n",
              "       [13. ],\n",
              "       [13.8],\n",
              "       [ 6.7],\n",
              "       [ 4.6],\n",
              "       [ 0.6],\n",
              "       [ 6.6],\n",
              "       [ 1.6],\n",
              "       [10.8],\n",
              "       [ 0.3],\n",
              "       [ 8.5],\n",
              "       [12.1],\n",
              "       [ 4.8],\n",
              "       [-2. ],\n",
              "       [13.7],\n",
              "       [ 5.3],\n",
              "       [ 7. ],\n",
              "       [ 7. ],\n",
              "       [ 6.4],\n",
              "       [ 2.2],\n",
              "       [ 7.5],\n",
              "       [ 4.2],\n",
              "       [ 4.2],\n",
              "       [10.5],\n",
              "       [ 1. ],\n",
              "       [13.8],\n",
              "       [ 7.8],\n",
              "       [13.2],\n",
              "       [13.3],\n",
              "       [10.9],\n",
              "       [-3.8],\n",
              "       [ 8.5],\n",
              "       [ 3.3],\n",
              "       [10. ],\n",
              "       [-4. ],\n",
              "       [ 0.6],\n",
              "       [14.5],\n",
              "       [11.9],\n",
              "       [14.3],\n",
              "       [ 9.7],\n",
              "       [12.3],\n",
              "       [-3.3],\n",
              "       [-4. ],\n",
              "       [12.6],\n",
              "       [ 8.4],\n",
              "       [-0.2],\n",
              "       [-4.7],\n",
              "       [ 5.3],\n",
              "       [ 0.6],\n",
              "       [ 3.4],\n",
              "       [-2. ],\n",
              "       [ 7.8],\n",
              "       [ 9.6],\n",
              "       [13. ],\n",
              "       [ 8.4],\n",
              "       [-0. ],\n",
              "       [ 4.5],\n",
              "       [ 4.8],\n",
              "       [-2.9],\n",
              "       [ 9.2],\n",
              "       [ 7.1],\n",
              "       [ 0.2],\n",
              "       [ 5.7],\n",
              "       [11.5],\n",
              "       [ 6.6],\n",
              "       [ 8.5],\n",
              "       [-4.7],\n",
              "       [ 2.4],\n",
              "       [-2.7],\n",
              "       [ 7.7],\n",
              "       [-4.9],\n",
              "       [14.7],\n",
              "       [ 0.1],\n",
              "       [ 7.8],\n",
              "       [ 0.7],\n",
              "       [ 8.8],\n",
              "       [13.5],\n",
              "       [12.1],\n",
              "       [ 9.9],\n",
              "       [-4.7],\n",
              "       [ 9.1],\n",
              "       [ 6. ],\n",
              "       [-1.6],\n",
              "       [10.4],\n",
              "       [12.5],\n",
              "       [ 8.4],\n",
              "       [ 4.9],\n",
              "       [-0.1],\n",
              "       [ 7.1],\n",
              "       [12.6],\n",
              "       [13.6],\n",
              "       [13.4],\n",
              "       [ 4.9],\n",
              "       [10.9],\n",
              "       [ 5.5],\n",
              "       [10.9],\n",
              "       [10.3],\n",
              "       [10. ],\n",
              "       [ 8.2],\n",
              "       [ 4.3],\n",
              "       [ 4.4],\n",
              "       [ 2.3],\n",
              "       [-2.4],\n",
              "       [-3.4],\n",
              "       [ 1.4],\n",
              "       [ 1.5],\n",
              "       [ 7.3],\n",
              "       [ 2.8],\n",
              "       [ 9.9],\n",
              "       [-2.7],\n",
              "       [ 7.6],\n",
              "       [-4.1],\n",
              "       [14.2],\n",
              "       [-1.6],\n",
              "       [-0.1],\n",
              "       [10.8],\n",
              "       [ 4.5],\n",
              "       [10. ],\n",
              "       [-1.7],\n",
              "       [12.7],\n",
              "       [ 4.1],\n",
              "       [-4.5],\n",
              "       [ 9.9],\n",
              "       [ 0.9],\n",
              "       [ 2.8],\n",
              "       [-0. ],\n",
              "       [ 3.4],\n",
              "       [ 4.9],\n",
              "       [ 1.1],\n",
              "       [-3.4],\n",
              "       [11.5],\n",
              "       [-1. ],\n",
              "       [ 5.4],\n",
              "       [10.4],\n",
              "       [-1.1],\n",
              "       [ 1.1],\n",
              "       [ 9.3],\n",
              "       [ 8.2],\n",
              "       [ 9.5],\n",
              "       [10.6],\n",
              "       [ 6.4],\n",
              "       [ 5.2],\n",
              "       [ 8.1],\n",
              "       [ 5.6],\n",
              "       [14.2],\n",
              "       [ 1.4],\n",
              "       [-1.6],\n",
              "       [10.1],\n",
              "       [10.3],\n",
              "       [ 5.5],\n",
              "       [-2.9],\n",
              "       [11.5],\n",
              "       [-2.3],\n",
              "       [ 2.2],\n",
              "       [ 0.6],\n",
              "       [ 5.2],\n",
              "       [-0.9],\n",
              "       [-3.8],\n",
              "       [-0. ],\n",
              "       [ 5.4],\n",
              "       [-2.9],\n",
              "       [ 9.3],\n",
              "       [ 9.3],\n",
              "       [10.3],\n",
              "       [12.6],\n",
              "       [ 2.1],\n",
              "       [ 5.1],\n",
              "       [ 7.4],\n",
              "       [-2.8],\n",
              "       [ 8.3],\n",
              "       [-3.9],\n",
              "       [11.7],\n",
              "       [11.1],\n",
              "       [ 9.7],\n",
              "       [ 2.7],\n",
              "       [-0.5],\n",
              "       [ 6.4],\n",
              "       [-3.3],\n",
              "       [-1. ],\n",
              "       [ 2.7],\n",
              "       [-0.5],\n",
              "       [ 0.7],\n",
              "       [-3.4],\n",
              "       [-0.4],\n",
              "       [13.4],\n",
              "       [ 7.7],\n",
              "       [ 5.7],\n",
              "       [-0.6],\n",
              "       [10.5],\n",
              "       [ 3.8],\n",
              "       [10.7],\n",
              "       [ 2.9],\n",
              "       [-3.1],\n",
              "       [-3.5],\n",
              "       [ 9.1],\n",
              "       [-3.3],\n",
              "       [-4.7],\n",
              "       [11.4],\n",
              "       [-4.8],\n",
              "       [-4.4],\n",
              "       [-4.1],\n",
              "       [ 3.2],\n",
              "       [-2.9],\n",
              "       [ 8.7],\n",
              "       [ 9.4],\n",
              "       [ 7.9],\n",
              "       [10. ],\n",
              "       [11.4],\n",
              "       [ 8.3],\n",
              "       [ 8.9],\n",
              "       [ 5.9],\n",
              "       [11.8],\n",
              "       [-0.4],\n",
              "       [ 6. ],\n",
              "       [ 2.6],\n",
              "       [14.7],\n",
              "       [-1.8],\n",
              "       [-2.4],\n",
              "       [10.2],\n",
              "       [ 3.1],\n",
              "       [ 1.7],\n",
              "       [ 7.1],\n",
              "       [ 6.9],\n",
              "       [ 9.4],\n",
              "       [-1.4],\n",
              "       [ 1.9],\n",
              "       [ 2.9],\n",
              "       [ 6.6],\n",
              "       [ 2.8],\n",
              "       [-1.4],\n",
              "       [ 5.1],\n",
              "       [-4. ],\n",
              "       [12.1],\n",
              "       [ 5. ],\n",
              "       [ 6.4],\n",
              "       [-2.3],\n",
              "       [-0.3],\n",
              "       [-0.7],\n",
              "       [ 7.8],\n",
              "       [ 8.9],\n",
              "       [ 7.1],\n",
              "       [13.3],\n",
              "       [11.3],\n",
              "       [ 8. ],\n",
              "       [11.8],\n",
              "       [12. ],\n",
              "       [ 6.3],\n",
              "       [ 3.6],\n",
              "       [ 5.1],\n",
              "       [-1.4],\n",
              "       [ 0.3],\n",
              "       [ 6. ],\n",
              "       [ 4.6],\n",
              "       [-3.2],\n",
              "       [ 3.5],\n",
              "       [ 6.1],\n",
              "       [-1.2],\n",
              "       [ 9.7],\n",
              "       [ 8.5],\n",
              "       [ 9.8],\n",
              "       [-3.9],\n",
              "       [ 2.6],\n",
              "       [ 1.9],\n",
              "       [ 6.1],\n",
              "       [-2.5],\n",
              "       [ 9.1],\n",
              "       [ 6.3],\n",
              "       [ 3.7],\n",
              "       [-2.8],\n",
              "       [-4.8],\n",
              "       [-0.9],\n",
              "       [10.2],\n",
              "       [ 0.9],\n",
              "       [ 7.4],\n",
              "       [-3.6],\n",
              "       [10.8],\n",
              "       [-0.3],\n",
              "       [-2.2],\n",
              "       [ 5.5],\n",
              "       [ 7.4],\n",
              "       [ 9. ],\n",
              "       [ 2.8],\n",
              "       [ 1.5],\n",
              "       [-3.2],\n",
              "       [-2.3],\n",
              "       [-0.3],\n",
              "       [ 1. ],\n",
              "       [ 2.6],\n",
              "       [-1.7],\n",
              "       [ 5.6],\n",
              "       [ 5.3],\n",
              "       [ 6.4],\n",
              "       [ 9. ],\n",
              "       [13.5],\n",
              "       [13.1],\n",
              "       [ 5. ],\n",
              "       [-2.5],\n",
              "       [11.4],\n",
              "       [ 2.8],\n",
              "       [ 0.5],\n",
              "       [-4.6],\n",
              "       [-3.5],\n",
              "       [12.9],\n",
              "       [ 9.6],\n",
              "       [-0.3],\n",
              "       [-3.9],\n",
              "       [10.6],\n",
              "       [-0.7],\n",
              "       [11.6],\n",
              "       [ 1.7],\n",
              "       [-2.4],\n",
              "       [11.9],\n",
              "       [ 6.1],\n",
              "       [ 3. ],\n",
              "       [ 6.2],\n",
              "       [13.2],\n",
              "       [ 4.2],\n",
              "       [ 2.8],\n",
              "       [11.7],\n",
              "       [10.3],\n",
              "       [ 5.6],\n",
              "       [-1.2],\n",
              "       [ 4. ],\n",
              "       [-2.7],\n",
              "       [13.1],\n",
              "       [-4.4],\n",
              "       [-4.5],\n",
              "       [-3.9],\n",
              "       [-4.1],\n",
              "       [ 9.7],\n",
              "       [ 6.5],\n",
              "       [12.2],\n",
              "       [ 7.1],\n",
              "       [ 9. ],\n",
              "       [-0.1],\n",
              "       [ 2.2],\n",
              "       [ 1.4],\n",
              "       [ 6.6],\n",
              "       [-0.4],\n",
              "       [-2.2],\n",
              "       [14.1],\n",
              "       [ 2.5],\n",
              "       [ 4.1],\n",
              "       [ 1.6],\n",
              "       [10.1],\n",
              "       [ 5.7],\n",
              "       [ 3. ],\n",
              "       [ 5.8],\n",
              "       [-3. ],\n",
              "       [10.9],\n",
              "       [ 7.9],\n",
              "       [-4.8],\n",
              "       [ 8.1],\n",
              "       [-2.8],\n",
              "       [ 6.8],\n",
              "       [ 3. ],\n",
              "       [ 6.6],\n",
              "       [ 0.4],\n",
              "       [-3.9],\n",
              "       [ 3.6],\n",
              "       [ 9.5],\n",
              "       [ 1.6],\n",
              "       [-4.7],\n",
              "       [-2.7],\n",
              "       [-1.9],\n",
              "       [ 4.6],\n",
              "       [ 1.3],\n",
              "       [10.6],\n",
              "       [ 3.3],\n",
              "       [-2.8],\n",
              "       [ 8.4],\n",
              "       [11.6],\n",
              "       [ 2.4],\n",
              "       [-4.5],\n",
              "       [13.1],\n",
              "       [ 1.2],\n",
              "       [ 7. ],\n",
              "       [-1.1],\n",
              "       [ 7.5],\n",
              "       [-2. ],\n",
              "       [ 4.1],\n",
              "       [ 6. ],\n",
              "       [ 2.2],\n",
              "       [10.4],\n",
              "       [14.2],\n",
              "       [14.3],\n",
              "       [-4.5],\n",
              "       [ 6.1],\n",
              "       [ 1.2],\n",
              "       [10.3],\n",
              "       [ 1.8],\n",
              "       [-3.8],\n",
              "       [ 2.5],\n",
              "       [-3. ],\n",
              "       [14.3],\n",
              "       [-2.8],\n",
              "       [ 4.2],\n",
              "       [11.6],\n",
              "       [-1.4],\n",
              "       [-0.1],\n",
              "       [ 9.1],\n",
              "       [10.8],\n",
              "       [-4.2],\n",
              "       [ 1.3],\n",
              "       [ 7.7],\n",
              "       [ 0.3],\n",
              "       [ 4.5],\n",
              "       [ 5.2],\n",
              "       [ 8. ],\n",
              "       [ 1.8],\n",
              "       [ 8.2],\n",
              "       [11.6],\n",
              "       [13.9],\n",
              "       [ 9.7],\n",
              "       [ 4.6],\n",
              "       [ 7.4],\n",
              "       [10.7],\n",
              "       [-3. ],\n",
              "       [-2.8],\n",
              "       [ 4.9],\n",
              "       [ 6.7],\n",
              "       [ 6.4],\n",
              "       [-3.5],\n",
              "       [14.5],\n",
              "       [14.3],\n",
              "       [ 5.6],\n",
              "       [ 3.4],\n",
              "       [-4.3],\n",
              "       [ 4.5],\n",
              "       [-1.3],\n",
              "       [-4.2],\n",
              "       [ 8.1],\n",
              "       [ 2.9],\n",
              "       [-4.7],\n",
              "       [ 0.7],\n",
              "       [ 8.3],\n",
              "       [ 4.6],\n",
              "       [ 0.2],\n",
              "       [14.2],\n",
              "       [-2.7],\n",
              "       [-3.1],\n",
              "       [ 5.9],\n",
              "       [ 6.6],\n",
              "       [ 6. ],\n",
              "       [ 9. ],\n",
              "       [ 1.6],\n",
              "       [ 3.6],\n",
              "       [ 6.1],\n",
              "       [11.4],\n",
              "       [12.4],\n",
              "       [10.1],\n",
              "       [-4.7],\n",
              "       [12.8],\n",
              "       [-2.1],\n",
              "       [12.4],\n",
              "       [ 5.6],\n",
              "       [ 1.7],\n",
              "       [ 4. ],\n",
              "       [ 4.3],\n",
              "       [-2.4],\n",
              "       [12.5],\n",
              "       [ 9.5],\n",
              "       [ 4.8],\n",
              "       [ 7.2],\n",
              "       [12. ],\n",
              "       [ 5.6],\n",
              "       [-1.8],\n",
              "       [-1.1],\n",
              "       [ 9.3],\n",
              "       [-1.4],\n",
              "       [10.9],\n",
              "       [ 7.5],\n",
              "       [ 7.2],\n",
              "       [-4.6],\n",
              "       [ 1. ],\n",
              "       [ 3.3],\n",
              "       [13.2],\n",
              "       [14.4],\n",
              "       [10.8],\n",
              "       [11.9],\n",
              "       [ 1.3],\n",
              "       [-2.6],\n",
              "       [10.5],\n",
              "       [11.6],\n",
              "       [ 8.6],\n",
              "       [ 2.4],\n",
              "       [ 2. ],\n",
              "       [-3.1],\n",
              "       [ 9.8],\n",
              "       [-3.7],\n",
              "       [ 4.8],\n",
              "       [12.4],\n",
              "       [ 6.4],\n",
              "       [ 6.4],\n",
              "       [ 2.1],\n",
              "       [ 9.9],\n",
              "       [12.3],\n",
              "       [ 5.5],\n",
              "       [ 3.7],\n",
              "       [14.1],\n",
              "       [-0.3],\n",
              "       [ 4.1],\n",
              "       [ 6.4],\n",
              "       [12.5],\n",
              "       [ 0.1],\n",
              "       [ 0.2],\n",
              "       [ 5.8],\n",
              "       [13.5],\n",
              "       [ 2.4],\n",
              "       [ 0.2],\n",
              "       [14.1],\n",
              "       [ 2.6],\n",
              "       [ 4.3],\n",
              "       [ 0. ],\n",
              "       [12.6],\n",
              "       [-1.8],\n",
              "       [-2.7],\n",
              "       [ 2.9],\n",
              "       [13.2],\n",
              "       [ 2.2],\n",
              "       [14.3],\n",
              "       [12.6],\n",
              "       [ 3.7],\n",
              "       [ 5.9],\n",
              "       [ 7.1],\n",
              "       [ 7.6],\n",
              "       [14.3],\n",
              "       [12.2],\n",
              "       [ 0. ],\n",
              "       [11.5],\n",
              "       [-2. ],\n",
              "       [-2. ]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W7FBYqlq1XnR",
        "colab_type": "text"
      },
      "source": [
        "## Plotting the output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mjxCN6vw1MhB",
        "colab_type": "code",
        "outputId": "473e1c27-5aba-473c-b052-001ab2f070c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "plt.plot(np.squeeze(model.predict_on_batch(training_data['inputs'])), np.squeeze(training_data['targets']))\n",
        "plt.xlabel('outputs')\n",
        "plt.ylabel('targets')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEGCAYAAABsLkJ6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tppy3a_M3XWx",
        "colab_type": "text"
      },
      "source": [
        "## Layers\n",
        "\n",
        "Layers are the building block of Neural Nets\n",
        "\n",
        "## Non-Linearities\n",
        "In order to have deep nets and find complex relationships through arbitrary functions, we need non-linearities.\n",
        "\n",
        "In ML non-linearities are also called activation functions.\n",
        "\n",
        "Activation functions transform inputs into outputs of a different kind.\n",
        "\n",
        "The four most use activation functions are:\n",
        "* Sigmoid (Logistic Function)\n",
        "* TanH (hyperbolic tangent\n",
        "* Relu (rectified linear unit)\n",
        "* softmax"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yC9CEBpt3V25",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_RQlQn97sbH",
        "colab_type": "text"
      },
      "source": [
        "## SoftMax\n",
        "The softmax transformation transforms a bunch of arbitrary large or small numbers into a valid probability distribution.\n",
        "\n",
        "A key aspect of the softmax transformation is that the valeus it outputs are in the range from 0 to 1. Their sum is exactly 1.\n",
        "\n",
        "\n",
        "## Backpropagation\n",
        "Consist of a single step; aligning the weights given the errors obtained.\n",
        "\n",
        "\n",
        "## Forwardpropagation\n",
        "Is the process of pushing inputs through the net. At the end of each epoch, the obtained outputs are compared to the targets to from the erros.\n",
        "\n",
        "The accuracy gotten by forward propagtting the dataset is the accuracy we expect the model to have if we deploy it in real life.\n",
        "\n",
        "## OverFitting\n",
        "Ways to deal with overfitting\n",
        "* Split the data into Test, Validation and Trainng Sets\n",
        "\n",
        "* **Early Stoping:** stop when updates becoe too small\n",
        "\n",
        "* **Use The N-Fold Cross-Validation:** where the dataset is too small\n",
        "\n",
        "* **Validation Set Strategy:** Stop when the validation loss starts incresing ro teh training loss becomes very small\n",
        "\n",
        "## Intialization\n",
        "It is the process in which we set the initail values of weights.\n",
        "\n",
        "**Types of Simple Initializations**\n",
        "\n",
        "1. Xavier's Initialization(Uniform and Normal): The main idea is that, the method is not so imoortant, the number of inputs and outputs is.\n",
        "\n",
        "* **Uniform Xavier Initialization:** draws each weight, w from a random uniform distribution.\n",
        "\n",
        "* **Normal Xavier Initialization:**\n",
        "\n",
        "\n",
        "## Optimizaton\n",
        "\n",
        "**Gradient Descent** A single gradient descen tis slow but willl eventually reach the minimum\n",
        "\n",
        "**SGD (Stochastic gradient descent:** Weights are updated many times inside a single epoch\n",
        "\n",
        "**Batching:** The process of splitting the dataset in n batches (mini-batches). Weights are updated after every batch instead epoch as in the case of SGD. It is more faster than the SGD.\n",
        "\n",
        "## Learning Rate Scheldules\n",
        "\n",
        "**Hyperparameters:** preset by the data scientist. comprises of width, depth and the learning rate, batch size, momentum coefficient, decay coefficient.\n",
        "\n",
        "**Parameters:** Found by optimizing. Comprises of weights and biases.\n",
        "\n",
        "For a proper learning rate:\n",
        "1. We start from a high initial learning rate\n",
        "2. At some point, we lower the rate to avoid oscillation\n",
        "3. Around the end, we pick a very small rate to get a precise answer.\n",
        "\n",
        "Exponential Scheldule: Still simple, but much better as it smoothly decays the learning rate.\n",
        "\n",
        "**Adaptive Learning Scheldules(AdaGrad-Adaptive gradient algorithm):** It dynamically varies the learning rate at each update and for each weight individually.\n",
        "Adagrad is smart, it's based on the training itself, adaption is per weight.\n",
        "\n",
        "**RMSprop (Root Mean Square propagation):** Similar to AdaGrad\n",
        "It adapts upwards and downwards since it;s not monotomous.\n",
        "\n",
        "**Aaptive Momemnt Estimation(ADAM):** It is the best learning method. plus, it is a new mehtod."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pPjYdG5HzA-T",
        "colab_type": "text"
      },
      "source": [
        "## Preprocessing\n",
        "\n",
        "Any manipulaton applied to the dataset beofre running it throught the model.\n",
        "\n",
        "**Motivation for Preprocessing DAta**\n",
        "* Compatibility: make data format suitable for libraries. e.g convert csv to .npz fiels for tensorflow librabry.\n",
        "*Orders of Magnitude:\n",
        "*Generalization: train models to be resused on new use cases.\n",
        "\n",
        "**Categorical Data**\n",
        "We encode categorical data in two ways:\n",
        "* One hot encoding: involes creating new columns for all categories. It is best when dealing with few categories.\n",
        "\n",
        "* Binary encoding: implies transforming the categories in to binaries. Even though binary encoding is helpul, its a bit promblematic. best when dealing with many categories."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkjfDt7c1-SY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}